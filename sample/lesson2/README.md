## 关于

* 学习 Python 时写一些简单的爬虫来获取需要的数据。
* 有些程序估计写的比较早,一些网站的验证机制估计也变了,只做参考用。
* 不定期更新。欢迎 PR。

## 爬虫实例

* Readme_Luowang:关于如何爬取落网音乐,下载到本地的小程序。
* Readme_Baidu:关于如何基于 Py2.7 根据关键词从百度下载图片的小程序。
* Readme_Zhihu:关于如何抓取知乎上一些信息的程序。
* Readme_One:关于如何爬取 One 网站上的每日一图以及 One 问答,并且存储在 LeanCloud 云后台。
* Readme_Sujin:关于如何爬取素锦网站上的好文章,并且存储在 LeanCloud 云后台。
* Readme_Douban:关于如何爬取豆瓣图书 Top250。
* Readme_Lagou:关于如何从拉勾网爬取较大量的职位信息以及存储至 NoSql 类型数据库中。
* Readme_XiciDaili:抄自知乎一个回答。改成 MongoDB 存储以及加了验证机制。但是可用性不是很高，大概30%。


## 爬虫基础

* [Scrapy 爬取豆瓣信息并用 MongoDB 存储](http://1992mrwang.blog.51cto.com/3265935/1583539)
* [Scrapy 爬取知乎用户数据并用 MySQL 存储](http://python.jobbole.com/85125/)
* [Python 爬虫技巧总结](http://www.codeceo.com/article/python-spider-skills.html#0-tsina-1-54529-397232819ff9a47a7b7e80a40613cfe1)
* [Python 爬虫学习系列教程](http://cuiqingcai.com/1052.html)
* [Python 工程师博客](http://zhuanlan.zhihu.com/xlz-d)

## 爬虫进阶 

* [Requests 库](http://cn.python-requests.org/zh_CN/latest/user/quickstart.html)
* [BeautifulSoup 库](http://beautifulsoup.readthedocs.io/zh_CN/latest/)
* [Scrapy 入门文档](http://scrapy-chs.readthedocs.org/zh_CN/0.24/intro/tutorial.html)
* [Scrapy 初级实战](http://www.ituring.com.cn/article/114408)
* [Scrapy 初级实战之数据可视化](http://aljun.me/post/9)
* [Python 抓取微信公众号文章](http://mp.weixin.qq.com/s?__biz=MzI0NjIxMzE5OQ==&mid=2656697797&idx=1&sn=a8e93bbc960c7564c2054a24e2414145#rd)
* [Python 模拟登陆知乎(8/7日更)](http://blog.csdn.net/think_ycx/article/details/52104529)
* [Python 与知乎相关的爬虫(8/21日更)](http://marcovaldong.github.io/2016/08/18/Python%E7%88%AC%E8%99%AB%E7%88%AC%E5%8F%96%E7%9F%A5%E4%B9%8E%E5%B0%8F%E7%BB%93/)
* Python 爬取知乎专栏文章推送至 Kindle

## 数据分析

* [用 pygal 来绘制SVG 显示数据](http://pygal.org/en/stable/documentation/types/line.html#time)
* [百度的良心之作 ECharts](http://echarts.baidu.com/demo.html#pie-roseType)

## Python 相关

* [Python2 中编码的问题](https://zhuanlan.zhihu.com/p/20612337?refer=xlz-d)

## 书籍推荐

* 《用 Python 进行数据分析》
* 《Python 数据挖掘入门与实战》
* 《干净的数据-数据清洗与入门实践》
* 《Python 网络数据采集》
* 《集体智慧编程》
* 《数据挖掘导论》

## 感谢

*  [suzumiyang](https://github.com/suzumiyang) 参与落网爬虫的改进

