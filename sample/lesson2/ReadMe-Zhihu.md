## 知乎爬虫

#####一：firstLogin模拟登录知乎--代码解读思路整理。
* 很多网站需要登录才能访问更多的内容，so登录必不可少，这部分代码也是我fork的源码的author.py（在第二部分可见，尊重作者，感谢：）
* 首先要想模拟登录，浏览器的工作原理一定要了解一点，推荐Chorme浏览器自带的审查元素（右键即可）然后观察Network的变化
* 模拟登录首先要构建Header请求头，这是让请求网站认为你是浏览器（not spider）
* 第二步要获取xsrf--详细请看http://baike.baidu.com/link?url=x5M7ywYtlBL5LDGsZ61VTJHzS582Y1uZnXgor_LszDF0k7-BY7RA8YwkJ02yxxk-hAANTw32wcHGRRl3Xqi2-a  我们要做的就是利用re或者bs去相应的网站获得这个参数，以证明我们不是坏银==
* 正确输入账号密码之后，肯定要输入验证码啦==简单的思路就是把验证码下载下来，然后人眼识别，手动填入（当然大神的源码中，能够直接破解，自动填写，但是在我的win7上好像不可以==）所以我稍微改了一下，用网页自动打开==
* 首次登陆成功之后，以后肯定不想重复再做这些啦，所以有cookie的存在啊~~注意一点：firstLogin代码执行并不是一开始就执行main函数--会先检查cookie==
* 在firstLogin代码里面有详细的步骤（删除了一些原来大神的完善代码），只是为了自己更好理解一下，思路更加清晰一些(尊重产权==)

#####二：getImgs爬取知乎问题下的图片--女生拥有短发是怎样一种体验？
* 这一小段代码作用是，从知乎网上down图片，之前看到一个帖子--女生短发是一种什么样的体验？看到里面好多美女图片，就想着全部下载下来==
* 登录的代码比较简单（大都大同小异），引用的是这位大牛写的author.py模块--https://github.com/wuchangfeng/zhihu-python--自己也在学习他的源码，down在工程里，索性直接引用了。十分欣赏。
* 遇到网页需要加载更多时候，思路我看了http://lovenight.github.io这位大牛的，后来发现1中的代码也有这一部分的处理，我就自己对着浏览器的请求以及1中大神的代码，写出来了。
* 之所以没有pull到1中大神project中,因为自己代码太渣。总之，会继续加上新的想法的。加油。

####三：getQuestion_topic爬取某个话题下面的所有问题。
* 输入“生活”这个话题时，浏览器返回http://www.zhihu.com/topic/19551147这个url，其中19551147就是这个话题的link-id。
* 上面那个link-id 很重要http://www.zhihu.com/topic/******/questions?page=# 。用link-id替换这个*****，用数字（1，2,3....）替换#
* 代码已写，思路以上。
* 可以文件存储或者数据库存储。
* 后面的自己不想写了，感觉没啥意思，准备爬全局问题，监测一天的问题导向。

####四：**getImgs**爬取知乎问题下的图片--女生拥有短发是怎样一种体验？
* 加上了Thread,Quene跑的快飞起了--五六分钟爬了1000条左右
* 加上的异常处理，碰到了不能下载下来的，直接跳过去
* 线程的知识参考[简书作者](http://www.jianshu.com/p/544d406e0875)**感谢**

####五：要干嘛？还没想好==
* 所有话题下面的问题http://www.zhihu.com/topic/19776751/top-answers

####六：getFocus批量关注某个话题下面的用户
* 详细请见代码
* 有点疑问 批量获得关注者 那个start参数有什么规律==
* 更新了最新的代码，start是十位数的时间戳
